{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15595ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotation_df: (6000, 6) <class 'pandas.core.frame.DataFrame'>\n",
      "transcription_df: (1, 6000) <class 'pandas.core.frame.DataFrame'>\n",
      "annotation_test_df: (2000, 6) <class 'pandas.core.frame.DataFrame'>\n",
      "transcription_test_df: (1, 2000) <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from pandas.api.types import is_scalar\n",
    "\n",
    "# Absolute project directory\n",
    "BASE_DIR = Path(\"/Users/nursultanatymtay/Desktop/Senior Project/Personality trait inference from text\")\n",
    "\n",
    "annotation_path = BASE_DIR / \"annotation_training.pkl\"\n",
    "transcription_path = BASE_DIR / \"transcription_training.pkl\"\n",
    "annotation_test_path = BASE_DIR / \"annotation_test.pkl\"\n",
    "transcription_test_path = BASE_DIR / \"transcription_test.pkl\"\n",
    "\n",
    "\n",
    "def load_pickle_as_dataframe(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Load a pickle file and ensure the result is a pandas DataFrame.\n",
    "\n",
    "    Handles:\n",
    "    - DataFrame (returned as-is)\n",
    "    - dict of scalars -> single-row DataFrame\n",
    "    - list of dicts -> DataFrame\n",
    "    - list/tuple of scalars -> single-column DataFrame\n",
    "    - any other scalar -> single-value DataFrame\n",
    "    \"\"\"\n",
    "    obj = pd.read_pickle(path)\n",
    "\n",
    "    if isinstance(obj, pd.DataFrame):\n",
    "        return obj\n",
    "\n",
    "    if isinstance(obj, dict):\n",
    "        # dict of scalars -> one row\n",
    "        if all(is_scalar(v) for v in obj.values()):\n",
    "            return pd.DataFrame([obj])\n",
    "        # otherwise try building from dict directly\n",
    "        try:\n",
    "            return pd.DataFrame(obj)\n",
    "        except Exception:\n",
    "            return pd.DataFrame.from_dict(obj, orient=\"index\").reset_index()\n",
    "\n",
    "    if isinstance(obj, (list, tuple)):\n",
    "        if len(obj) == 0:\n",
    "            return pd.DataFrame()\n",
    "        first = obj[0]\n",
    "        if isinstance(first, dict):\n",
    "            return pd.DataFrame(list(obj))\n",
    "        if all(is_scalar(x) for x in obj):\n",
    "            return pd.DataFrame({\"value\": list(obj)})\n",
    "        # fallback\n",
    "        return pd.DataFrame(list(obj))\n",
    "\n",
    "    if is_scalar(obj):\n",
    "        return pd.DataFrame({\"value\": [obj]})\n",
    "\n",
    "    # final fallback\n",
    "    try:\n",
    "        return pd.DataFrame(obj)\n",
    "    except Exception as exc:\n",
    "        raise TypeError(f\"Pickle at {path} could not be converted to a DataFrame. Type: {type(obj)}\") from exc\n",
    "\n",
    "\n",
    "annotation_df = load_pickle_as_dataframe(annotation_path)\n",
    "transcription_df = load_pickle_as_dataframe(transcription_path)\n",
    "annotation_test_df = load_pickle_as_dataframe(annotation_test_path)\n",
    "transcription_test_df = load_pickle_as_dataframe(transcription_test_path)\n",
    "\n",
    "print(\"annotation_df:\", annotation_df.shape, type(annotation_df))\n",
    "print(\"transcription_df:\", transcription_df.shape, type(transcription_df))\n",
    "print(\"annotation_test_df:\", annotation_test_df.shape, type(annotation_test_df))\n",
    "print(\"transcription_test_df:\", transcription_test_df.shape, type(transcription_test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f212d1be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>J4GQm9j0JZ0.003.mp4</td>\n",
       "      <td>He's cutting it and then turn around and see the end result, but I'm glad he didn't do that because I probably would've lost my mind. As it was getting cut, I was just excited. I saw the snippets of hair falling to the floor and I was like, \"Yes!\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zEyRyTnIw5I.005.mp4</td>\n",
       "      <td>Responsibility to house the organ I had been given and I needed to tell them I was going to take good care of that organ and that I so appreciated what they had done. Almost immediately I sent a letter to them</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nskJh7v6v1U.004.mp4</td>\n",
       "      <td>I actually got quite a few sets of black pens this year, because I bought one pack. I think I bought two packs, actually, that I really liked, and then I found ... Some people at my work had these really cool pens that I liked a lot, and I liked how they wrote-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  file  \\\n",
       "0  J4GQm9j0JZ0.003.mp4   \n",
       "1  zEyRyTnIw5I.005.mp4   \n",
       "2  nskJh7v6v1U.004.mp4   \n",
       "\n",
       "                                                                                                                                                                                                                                                                    text  \n",
       "0                He's cutting it and then turn around and see the end result, but I'm glad he didn't do that because I probably would've lost my mind. As it was getting cut, I was just excited. I saw the snippets of hair falling to the floor and I was like, \"Yes!\"  \n",
       "1                                                      Responsibility to house the organ I had been given and I needed to tell them I was going to take good care of that organ and that I so appreciated what they had done. Almost immediately I sent a letter to them  \n",
       "2  I actually got quite a few sets of black pens this year, because I bought one pack. I think I bought two packs, actually, that I really liked, and then I found ... Some people at my work had these really cool pens that I liked a lot, and I liked how they wrote-  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>htH89DBizno.004.mp4</td>\n",
       "      <td>... Going nuts from another room, run in there to check, there's no [inaudible 00:00:37], but it was like the [scissors 00:00:35] aren't there. Now maybe I'm just not sleeping enough that I moved the scissors somewhere, but I swear the-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p_wf-KszNlk.001.mp4</td>\n",
       "      <td>I've got a little bit to go but we need you there so...I have decided to do a Q&amp;A video. Obviously I'm going to need you guy's help with that, or girls. Goddamn, now I'm going to get killed by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MuYYY3XaJ7Q.001.mp4</td>\n",
       "      <td>A video's quality over quantity, so everyone can have a chance to watch it and that's why I've been doing 2 to 3 days before each video. I've had a couple of people asking me about that. That's just like a quick little thing, trying to spice up this video.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  file  \\\n",
       "0  htH89DBizno.004.mp4   \n",
       "1  p_wf-KszNlk.001.mp4   \n",
       "2  MuYYY3XaJ7Q.001.mp4   \n",
       "\n",
       "                                                                                                                                                                                                                                                               text  \n",
       "0                      ... Going nuts from another room, run in there to check, there's no [inaudible 00:00:37], but it was like the [scissors 00:00:35] aren't there. Now maybe I'm just not sleeping enough that I moved the scissors somewhere, but I swear the-  \n",
       "1                                                                  I've got a little bit to go but we need you there so...I have decided to do a Q&A video. Obviously I'm going to need you guy's help with that, or girls. Goddamn, now I'm going to get killed by  \n",
       "2  A video's quality over quantity, so everyone can have a chance to watch it and that's why I've been doing 2 to 3 days before each video. I've had a couple of people asking me about that. That's just like a quick little thing, trying to spice up this video.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)   # don't truncate long strings\n",
    "pd.set_option('display.max_columns', None)    # show all columns\n",
    "pd.set_option('display.width', 0)             # let pandas use full cell width\n",
    "\n",
    "transcription_df_T = transcription_df.T\n",
    "transcription_df_T = transcription_df_T.rename(columns={0: \"text\"})\n",
    "transcription_df_T=transcription_df_T.reset_index().rename(columns={'index':'file'})\n",
    "\n",
    "display(transcription_df_T.head(3))\n",
    "\n",
    "# Transpose and prepare transcription_test_df similarly to training\n",
    "transcription_test_df_T = transcription_test_df.T\n",
    "transcription_test_df_T = transcription_test_df_T.rename(columns={0: \"text\"})\n",
    "transcription_test_df_T=transcription_test_df_T.reset_index().rename(columns={'index':'file'})\n",
    "display(transcription_test_df_T.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b764af78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>extraversion</th>\n",
       "      <th>neuroticism</th>\n",
       "      <th>agreeableness</th>\n",
       "      <th>conscientiousness</th>\n",
       "      <th>interview</th>\n",
       "      <th>openness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>J4GQm9j0JZ0.003.mp4</td>\n",
       "      <td>0.523364</td>\n",
       "      <td>0.552083</td>\n",
       "      <td>0.626374</td>\n",
       "      <td>0.601942</td>\n",
       "      <td>0.504673</td>\n",
       "      <td>0.488889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zEyRyTnIw5I.005.mp4</td>\n",
       "      <td>0.345794</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.472527</td>\n",
       "      <td>0.582524</td>\n",
       "      <td>0.457944</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nskJh7v6v1U.004.mp4</td>\n",
       "      <td>0.252336</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.406593</td>\n",
       "      <td>0.485437</td>\n",
       "      <td>0.373832</td>\n",
       "      <td>0.511111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6wHQsN5g2RM.000.mp4</td>\n",
       "      <td>0.457944</td>\n",
       "      <td>0.489583</td>\n",
       "      <td>0.505495</td>\n",
       "      <td>0.398058</td>\n",
       "      <td>0.457944</td>\n",
       "      <td>0.377778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dQOeQYWIgm8.000.mp4</td>\n",
       "      <td>0.607477</td>\n",
       "      <td>0.489583</td>\n",
       "      <td>0.406593</td>\n",
       "      <td>0.621359</td>\n",
       "      <td>0.570093</td>\n",
       "      <td>0.622222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>eHcRre1YsNA.000.mp4</td>\n",
       "      <td>0.196262</td>\n",
       "      <td>0.302083</td>\n",
       "      <td>0.351648</td>\n",
       "      <td>0.262136</td>\n",
       "      <td>0.214953</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vZpneJlniAE.005.mp4</td>\n",
       "      <td>0.420561</td>\n",
       "      <td>0.635417</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.466019</td>\n",
       "      <td>0.532710</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>oANKg9_grdA.004.mp4</td>\n",
       "      <td>0.429907</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.626374</td>\n",
       "      <td>0.582524</td>\n",
       "      <td>0.551402</td>\n",
       "      <td>0.588889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>VuadgOz6T7s.000.mp4</td>\n",
       "      <td>0.224299</td>\n",
       "      <td>0.135417</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.145631</td>\n",
       "      <td>0.140187</td>\n",
       "      <td>0.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7nhJXn9PI0I.001.mp4</td>\n",
       "      <td>0.177570</td>\n",
       "      <td>0.197917</td>\n",
       "      <td>0.186813</td>\n",
       "      <td>0.417476</td>\n",
       "      <td>0.224299</td>\n",
       "      <td>0.355556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  file  extraversion  neuroticism  agreeableness  \\\n",
       "0  J4GQm9j0JZ0.003.mp4      0.523364     0.552083       0.626374   \n",
       "1  zEyRyTnIw5I.005.mp4      0.345794     0.375000       0.472527   \n",
       "2  nskJh7v6v1U.004.mp4      0.252336     0.291667       0.406593   \n",
       "3  6wHQsN5g2RM.000.mp4      0.457944     0.489583       0.505495   \n",
       "4  dQOeQYWIgm8.000.mp4      0.607477     0.489583       0.406593   \n",
       "5  eHcRre1YsNA.000.mp4      0.196262     0.302083       0.351648   \n",
       "6  vZpneJlniAE.005.mp4      0.420561     0.635417       0.571429   \n",
       "7  oANKg9_grdA.004.mp4      0.429907     0.583333       0.626374   \n",
       "8  VuadgOz6T7s.000.mp4      0.224299     0.135417       0.153846   \n",
       "9  7nhJXn9PI0I.001.mp4      0.177570     0.197917       0.186813   \n",
       "\n",
       "   conscientiousness  interview  openness  \n",
       "0           0.601942   0.504673  0.488889  \n",
       "1           0.582524   0.457944  0.366667  \n",
       "2           0.485437   0.373832  0.511111  \n",
       "3           0.398058   0.457944  0.377778  \n",
       "4           0.621359   0.570093  0.622222  \n",
       "5           0.262136   0.214953  0.566667  \n",
       "6           0.466019   0.532710  0.633333  \n",
       "7           0.582524   0.551402  0.588889  \n",
       "8           0.145631   0.140187  0.233333  \n",
       "9           0.417476   0.224299  0.355556  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>extraversion</th>\n",
       "      <th>neuroticism</th>\n",
       "      <th>agreeableness</th>\n",
       "      <th>conscientiousness</th>\n",
       "      <th>interview</th>\n",
       "      <th>openness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>htH89DBizno.004.mp4</td>\n",
       "      <td>0.485981</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.681319</td>\n",
       "      <td>0.669903</td>\n",
       "      <td>0.626168</td>\n",
       "      <td>0.822222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p_wf-KszNlk.001.mp4</td>\n",
       "      <td>0.616822</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.514563</td>\n",
       "      <td>0.570093</td>\n",
       "      <td>0.655556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MuYYY3XaJ7Q.001.mp4</td>\n",
       "      <td>0.467290</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.560440</td>\n",
       "      <td>0.524272</td>\n",
       "      <td>0.514019</td>\n",
       "      <td>0.522222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0MB91ku0eEw.005.mp4</td>\n",
       "      <td>0.411215</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.660194</td>\n",
       "      <td>0.570093</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WpEZOSrENL0.003.mp4</td>\n",
       "      <td>0.317757</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.524272</td>\n",
       "      <td>0.448598</td>\n",
       "      <td>0.411111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C2Y9Puk3Obk.004.mp4</td>\n",
       "      <td>0.831776</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.708738</td>\n",
       "      <td>0.850467</td>\n",
       "      <td>0.822222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ask-ZFRztf8.003.mp4</td>\n",
       "      <td>0.467290</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.439560</td>\n",
       "      <td>0.592233</td>\n",
       "      <td>0.504673</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TSGpD2NBeCQ.005.mp4</td>\n",
       "      <td>0.467290</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.670330</td>\n",
       "      <td>0.553398</td>\n",
       "      <td>0.579439</td>\n",
       "      <td>0.677778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>54JawR1x0II.004.mp4</td>\n",
       "      <td>0.429907</td>\n",
       "      <td>0.489583</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.601942</td>\n",
       "      <td>0.570093</td>\n",
       "      <td>0.588889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9n8dNi-ERQ0.001.mp4</td>\n",
       "      <td>0.542056</td>\n",
       "      <td>0.572917</td>\n",
       "      <td>0.472527</td>\n",
       "      <td>0.466019</td>\n",
       "      <td>0.542056</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  file  extraversion  neuroticism  agreeableness  \\\n",
       "0  htH89DBizno.004.mp4      0.485981     0.645833       0.681319   \n",
       "1  p_wf-KszNlk.001.mp4      0.616822     0.593750       0.692308   \n",
       "2  MuYYY3XaJ7Q.001.mp4      0.467290     0.625000       0.560440   \n",
       "3  0MB91ku0eEw.005.mp4      0.411215     0.458333       0.714286   \n",
       "4  WpEZOSrENL0.003.mp4      0.317757     0.437500       0.384615   \n",
       "5  C2Y9Puk3Obk.004.mp4      0.831776     0.843750       0.923077   \n",
       "6  ask-ZFRztf8.003.mp4      0.467290     0.531250       0.439560   \n",
       "7  TSGpD2NBeCQ.005.mp4      0.467290     0.604167       0.670330   \n",
       "8  54JawR1x0II.004.mp4      0.429907     0.489583       0.615385   \n",
       "9  9n8dNi-ERQ0.001.mp4      0.542056     0.572917       0.472527   \n",
       "\n",
       "   conscientiousness  interview  openness  \n",
       "0           0.669903   0.626168  0.822222  \n",
       "1           0.514563   0.570093  0.655556  \n",
       "2           0.524272   0.514019  0.522222  \n",
       "3           0.660194   0.570093  0.400000  \n",
       "4           0.524272   0.448598  0.411111  \n",
       "5           0.708738   0.850467  0.822222  \n",
       "6           0.592233   0.504673  0.555556  \n",
       "7           0.553398   0.579439  0.677778  \n",
       "8           0.601942   0.570093  0.588889  \n",
       "9           0.466019   0.542056  0.466667  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "annotation_df = annotation_df.reset_index().rename(columns={'index':'file'})\n",
    "annotation_test_df = annotation_test_df.reset_index().rename(columns={'index':'file'})\n",
    "\n",
    "display(annotation_df.head(10))\n",
    "display(annotation_test_df.head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbfee228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>extraversion</th>\n",
       "      <th>neuroticism</th>\n",
       "      <th>agreeableness</th>\n",
       "      <th>conscientiousness</th>\n",
       "      <th>openness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>J4GQm9j0JZ0.003.mp4</td>\n",
       "      <td>He's cutting it and then turn around and see the end result, but I'm glad he didn't do that because I probably would've lost my mind. As it was getting cut, I was just excited. I saw the snippets of hair falling to the floor and I was like, \"Yes!\"</td>\n",
       "      <td>0.523364</td>\n",
       "      <td>0.552083</td>\n",
       "      <td>0.626374</td>\n",
       "      <td>0.601942</td>\n",
       "      <td>0.488889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zEyRyTnIw5I.005.mp4</td>\n",
       "      <td>Responsibility to house the organ I had been given and I needed to tell them I was going to take good care of that organ and that I so appreciated what they had done. Almost immediately I sent a letter to them</td>\n",
       "      <td>0.345794</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.472527</td>\n",
       "      <td>0.582524</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nskJh7v6v1U.004.mp4</td>\n",
       "      <td>I actually got quite a few sets of black pens this year, because I bought one pack. I think I bought two packs, actually, that I really liked, and then I found ... Some people at my work had these really cool pens that I liked a lot, and I liked how they wrote-</td>\n",
       "      <td>0.252336</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.406593</td>\n",
       "      <td>0.485437</td>\n",
       "      <td>0.511111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  file  \\\n",
       "0  J4GQm9j0JZ0.003.mp4   \n",
       "1  zEyRyTnIw5I.005.mp4   \n",
       "2  nskJh7v6v1U.004.mp4   \n",
       "\n",
       "                                                                                                                                                                                                                                                                    text  \\\n",
       "0                He's cutting it and then turn around and see the end result, but I'm glad he didn't do that because I probably would've lost my mind. As it was getting cut, I was just excited. I saw the snippets of hair falling to the floor and I was like, \"Yes!\"   \n",
       "1                                                      Responsibility to house the organ I had been given and I needed to tell them I was going to take good care of that organ and that I so appreciated what they had done. Almost immediately I sent a letter to them   \n",
       "2  I actually got quite a few sets of black pens this year, because I bought one pack. I think I bought two packs, actually, that I really liked, and then I found ... Some people at my work had these really cool pens that I liked a lot, and I liked how they wrote-   \n",
       "\n",
       "   extraversion  neuroticism  agreeableness  conscientiousness  openness  \n",
       "0      0.523364     0.552083       0.626374           0.601942  0.488889  \n",
       "1      0.345794     0.375000       0.472527           0.582524  0.366667  \n",
       "2      0.252336     0.291667       0.406593           0.485437  0.511111  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>extraversion</th>\n",
       "      <th>neuroticism</th>\n",
       "      <th>agreeableness</th>\n",
       "      <th>conscientiousness</th>\n",
       "      <th>openness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>htH89DBizno.004.mp4</td>\n",
       "      <td>... Going nuts from another room, run in there to check, there's no [inaudible 00:00:37], but it was like the [scissors 00:00:35] aren't there. Now maybe I'm just not sleeping enough that I moved the scissors somewhere, but I swear the-</td>\n",
       "      <td>0.485981</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.681319</td>\n",
       "      <td>0.669903</td>\n",
       "      <td>0.822222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p_wf-KszNlk.001.mp4</td>\n",
       "      <td>I've got a little bit to go but we need you there so...I have decided to do a Q&amp;A video. Obviously I'm going to need you guy's help with that, or girls. Goddamn, now I'm going to get killed by</td>\n",
       "      <td>0.616822</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.514563</td>\n",
       "      <td>0.655556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MuYYY3XaJ7Q.001.mp4</td>\n",
       "      <td>A video's quality over quantity, so everyone can have a chance to watch it and that's why I've been doing 2 to 3 days before each video. I've had a couple of people asking me about that. That's just like a quick little thing, trying to spice up this video.</td>\n",
       "      <td>0.467290</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.560440</td>\n",
       "      <td>0.524272</td>\n",
       "      <td>0.522222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  file  \\\n",
       "0  htH89DBizno.004.mp4   \n",
       "1  p_wf-KszNlk.001.mp4   \n",
       "2  MuYYY3XaJ7Q.001.mp4   \n",
       "\n",
       "                                                                                                                                                                                                                                                               text  \\\n",
       "0                      ... Going nuts from another room, run in there to check, there's no [inaudible 00:00:37], but it was like the [scissors 00:00:35] aren't there. Now maybe I'm just not sleeping enough that I moved the scissors somewhere, but I swear the-   \n",
       "1                                                                  I've got a little bit to go but we need you there so...I have decided to do a Q&A video. Obviously I'm going to need you guy's help with that, or girls. Goddamn, now I'm going to get killed by   \n",
       "2  A video's quality over quantity, so everyone can have a chance to watch it and that's why I've been doing 2 to 3 days before each video. I've had a couple of people asking me about that. That's just like a quick little thing, trying to spice up this video.   \n",
       "\n",
       "   extraversion  neuroticism  agreeableness  conscientiousness  openness  \n",
       "0      0.485981     0.645833       0.681319           0.669903  0.822222  \n",
       "1      0.616822     0.593750       0.692308           0.514563  0.655556  \n",
       "2      0.467290     0.625000       0.560440           0.524272  0.522222  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "annotation_transcription_train = pd.merge(transcription_df_T, annotation_df, on='file')\n",
    "annotation_transcription_train = annotation_transcription_train.drop(columns=['interview'], errors='ignore')\n",
    "\n",
    "display(annotation_transcription_train.head(3))\n",
    "\n",
    "annotation_transcription_test = pd.merge(transcription_test_df_T, annotation_test_df, on='file')\n",
    "annotation_transcription_test = annotation_transcription_test.drop(columns=['interview'], errors='ignore')\n",
    "\n",
    "display(annotation_transcription_test.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f815171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5ca483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI personality analysis functions loaded!\n",
      "Using OpenAI API v1.0+ client format\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "import os\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "# Set up OpenAI client (you'll need to set this)\n",
    "# You can set it as an environment variable or directly here\n",
    "client = OpenAI(\n",
    "    api_key=\" \"\n",
    ")\n",
    "# Or use environment variable:\n",
    "# client = OpenAI()  # This will automatically use OPENAI_API_KEY environment variable\n",
    "\n",
    "def get_personality_traits_gpt(text: str, model: str = \"gpt-5-nano-2025-08-07\") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Calls OpenAI API to analyze personality traits from text using the Big Five model.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The text to analyze\n",
    "        model (str): OpenAI model to use (e.g., \"gpt-4\", \"gpt-3.5-turbo\")\n",
    "    \n",
    "    Returns:\n",
    "        Dict containing traits and scores, or error information\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"You are a careful, evidence-based psychologist who specialises in the Big Five (OCEAN) personality model.  \n",
    "Your job is to infer approximate **Big Five trait scores** from a piece of text.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Task\n",
    "\n",
    "Given an input **TEXT** that reflects a person's writing (messages, essays, posts, etc.), estimate their stable personality tendencies along the **Big Five** dimensions:\n",
    "\n",
    "- Agreeableness  \n",
    "- Neuroticism  \n",
    "- Openness to Experience  \n",
    "- Conscientiousness  \n",
    "- Extraversion  \n",
    "\n",
    "You must output **only** numeric scores between **0.0 and 1.0** (inclusive), where:\n",
    "\n",
    "- 0.0 = extremely low on this trait  \n",
    "- 0.5 = average / unsure  \n",
    "- 1.0 = extremely high on this trait  \n",
    "\n",
    "Use two or three decimal places.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Conceptual guides (use these when interpreting the text)\n",
    "\n",
    "**Openness to Experience**  \n",
    "- High: appreciates art, emotion, beauty, imagination, curiosity, variety, and unusual ideas; likes trying new things; creative, intellectually curious, uses rich/vivid language, reflects on abstract ideas; may hold unconventional beliefs and seek intense or euphoric experiences.  \n",
    "- Low: prefers routine and familiarity; pragmatic, data-driven, and focused on practicality; disinterested in abstract or imaginative topics; can appear dogmatic or closed-minded.\n",
    "\n",
    "**Conscientiousness**  \n",
    "- High: self-disciplined, organised, dutiful, goal- and achievement-oriented; likes order, schedules, and planning; completes tasks promptly, pays attention to details, takes obligations seriously; behaviour is controlled and reliable.  \n",
    "- Low: flexible and spontaneous but can be disorganised, messy, unreliable; procrastinates, forgets or abandons tasks; tends to \"wing it\" instead of planning carefully.\n",
    "\n",
    "**Extraversion**  \n",
    "- High: energetic, talkative, outgoing; enjoys social interaction and being around people; seeks external stimulation; starts conversations, likes being the centre of attention, active and enthusiastic in groups.  \n",
    "- Low (introversion): quiet, reserved, low-key; prefers depth over breadth in social contacts; may avoid being centre of attention, keeps in the background; needs more time alone and less external stimulation, but is not necessarily unfriendly or depressed.\n",
    "\n",
    "**Agreeableness**  \n",
    "- High: kind, considerate, trusting and trustworthy, generous, compassionate; interested in others, takes time to help, feels others' emotions, makes people feel at ease; values social harmony and cooperation, optimistic about others' motives.  \n",
    "- Low: puts own interests first; more skeptical or suspicious of others' motives; can be unfriendly, blunt, competitive, argumentative, or uncooperative; less concerned with others' problems or well-being.\n",
    "\n",
    "**Neuroticism**  \n",
    "- High: emotionally volatile and reactive; prone to strong negative emotions (anxiety, worry, anger, sadness); easily stressed or upset; mood swings, frequent irritability, pessimism; interprets situations as threatening or overwhelming, ruminates on problems.  \n",
    "- Low (emotional stability): calm, even-tempered; less easily upset or stressed; negative emotions fade more quickly; generally emotionally stable and resilient (this does **not** automatically mean very positive or cheerful—that is more related to extraversion).\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Important instructions\n",
    "\n",
    "1. **Base your judgement only on the TEXT.**  \n",
    "   - Do not assume traits that are not supported by evidence in the text.  \n",
    "   - If the text is very short or ambiguous for a trait, keep that trait closer to **0.5** (uncertain/average).\n",
    "\n",
    "2. **Focus on stable tendencies**, not temporary moods.  \n",
    "   - Look for patterns in how the person talks about themselves, others, work, feelings, plans, and experiences.\n",
    "\n",
    "3. **Use the full 0–1 range** when justified.  \n",
    "   - Very strong, repeated signals of a trait → move closer to 0.1 or 0.9+.  \n",
    "   - Neutral or mixed signals → keep near 0.4–0.6.  \n",
    "   - Strong evidence of the opposite pole → move toward 0.0–0.2.\n",
    "\n",
    "4. **No explanation in the final answer.**  \n",
    "   - Internally you may reason, but your final output must strictly follow the required JSON format below, with no extra text.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Output format (MUST follow exactly)\n",
    "\n",
    "Return **exactly one JSON object** with:\n",
    "\n",
    "- `\"traits\"`: array of trait names in this exact order  \n",
    "  `[\"Agreeableness\", \"Neuroticism\", \"Openness\", \"Conscientiousness\", \"Extraversion\"]`\n",
    "- `\"scores\"`: array of 5 floating-point numbers in the same order, each between 0.0 and 1.0 (inclusive), with 2–3 decimal places.\n",
    "\n",
    "**Example of valid output format (structure only):**\n",
    "\n",
    "    {{\n",
    "      \"traits\": [\"Agreeableness\", \"Neuroticism\", \"Openness\", \"Conscientiousness\", \"Extraversion\"],\n",
    "      \"scores\": [0.72, 0.31, 0.84, 0.59, 0.46]\n",
    "    }}\n",
    "\n",
    "Do **not** add comments, explanations, or any additional keys.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Now analyse this text\n",
    "\n",
    "TEXT:\n",
    "{text}\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a professional psychologist specializing in personality assessment using the Big Five model.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Extract the response text\n",
    "        response_text = response.choices[0].message.content.strip()\n",
    "        \n",
    "        # Try to parse as JSON\n",
    "        try:\n",
    "            result = json.loads(response_text)\n",
    "            return result\n",
    "        except json.JSONDecodeError:\n",
    "            # If JSON parsing fails, return the raw response for debugging\n",
    "            return {\n",
    "                \"error\": \"JSON parsing failed\",\n",
    "                \"raw_response\": response_text\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"error\": str(e),\n",
    "            \"type\": type(e).__name__\n",
    "        }\n",
    "\n",
    "# Example usage function\n",
    "def analyze_personality_batch(texts: List[str], model: str = \"gpt-4\") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Analyze personality traits for a batch of texts.\n",
    "    \n",
    "    Args:\n",
    "        texts (List[str]): List of texts to analyze\n",
    "        model (str): OpenAI model to use\n",
    "    \n",
    "    Returns:\n",
    "        List of dictionaries containing results for each text\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for i, text in enumerate(texts):\n",
    "        print(f\"Analyzing text {i+1}/{len(texts)}...\")\n",
    "        result = get_personality_traits_gpt(text, model)\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "print(\"OpenAI personality analysis functions loaded!\")\n",
    "print(\"Using OpenAI API v1.0+ client format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50dc2e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing personality analysis...\n",
      "Result:\n",
      "{\n",
      "  \"traits\": [\n",
      "    \"Agreeableness\",\n",
      "    \"Neuroticism\",\n",
      "    \"Openness\",\n",
      "    \"Conscientiousness\",\n",
      "    \"Extraversion\"\n",
      "  ],\n",
      "  \"scores\": [\n",
      "    0.78,\n",
      "    0.25,\n",
      "    0.5,\n",
      "    0.92,\n",
      "    0.4\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Test the personality analysis function\n",
    "# Make sure you have set your OpenAI API key first!\n",
    "\n",
    "# Example text for testing\n",
    "sample_text = \"\"\"\n",
    "Thank you for this opportunity. I am a fast-working, diligent and self-disciplined employee with the skills to meet the demands of the role. I have a track record of achievement. I attained excellent grades in my chosen subjects at college and in previous roles, I was recognised for my trustworthiness, strong work ethic and collaboration skills. If you hire me, I will be a positive role model for the company and work hard to ensure I give you a solid return on my salary.\n",
    "\"\"\"\n",
    "\n",
    "# Test with a single text\n",
    "try:\n",
    "    print(\"Testing personality analysis...\")\n",
    "    result = get_personality_traits_gpt(sample_text)\n",
    "    print(\"Result:\")\n",
    "    print(json.dumps(result, indent=2))\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {e}\")\n",
    "    print(\"Make sure your OpenAI API key is correctly set!\")\n",
    "\n",
    "# Example of how to analyze your training data\n",
    "# (uncomment and run when you have API key set up and tested)\n",
    "\n",
    "# print(\"\\nAnalyzing first 3 training samples...\")\n",
    "# sample_texts = annotation_transcription_train['text'].head(3).tolist()\n",
    "# results = analyze_personality_batch(sample_texts)\n",
    "# for i, result in enumerate(results):\n",
    "#     print(f\"\\nSample {i+1} result:\")\n",
    "#     print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8864aa52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 10 test samples...\n",
      "Columns in test data: ['file', 'text', 'extraversion', 'neuroticism', 'agreeableness', 'conscientiousness', 'openness']\n",
      "\n",
      "Running GPT analysis on test samples...\n",
      "Analyzing text 1/10...\n",
      "Analyzing text 2/10...\n",
      "Analyzing text 3/10...\n",
      "Analyzing text 4/10...\n",
      "Analyzing text 5/10...\n",
      "Analyzing text 6/10...\n",
      "Analyzing text 7/10...\n",
      "Analyzing text 8/10...\n",
      "Analyzing text 9/10...\n",
      "Analyzing text 10/10...\n",
      "\n",
      "================================================================================\n",
      "RESULTS:\n",
      "================================================================================\n",
      "\n",
      "--- Sample 1 ---\n",
      "Text preview: ... Going nuts from another room, run in there to check, there's no [inaudible 00:00:37], but it was...\n",
      "\n",
      "GPT Predictions:\n",
      "  Agreeableness       : 0.500\n",
      "  Neuroticism         : 0.700\n",
      "  Openness            : 0.450\n",
      "  Conscientiousness   : 0.350\n",
      "  Extraversion        : 0.450\n",
      "\n",
      "Ground Truth:\n",
      "  Agreeableness       : 0.681\n",
      "  Neuroticism         : 0.646\n",
      "  Openness            : 0.822\n",
      "  Conscientiousness   : 0.670\n",
      "  Extraversion        : 0.486\n",
      "\n",
      "Absolute Errors:\n",
      "  Agreeableness       : 0.181\n",
      "  Neuroticism         : 0.054\n",
      "  Openness            : 0.372\n",
      "  Conscientiousness   : 0.320\n",
      "  Extraversion        : 0.036\n",
      "\n",
      "--- Sample 2 ---\n",
      "Text preview: I've got a little bit to go but we need you there so...I have decided to do a Q&A video. Obviously I...\n",
      "\n",
      "GPT Predictions:\n",
      "  Agreeableness       : 0.680\n",
      "  Neuroticism         : 0.400\n",
      "  Openness            : 0.500\n",
      "  Conscientiousness   : 0.500\n",
      "  Extraversion        : 0.750\n",
      "\n",
      "Ground Truth:\n",
      "  Agreeableness       : 0.692\n",
      "  Neuroticism         : 0.594\n",
      "  Openness            : 0.656\n",
      "  Conscientiousness   : 0.515\n",
      "  Extraversion        : 0.617\n",
      "\n",
      "Absolute Errors:\n",
      "  Agreeableness       : 0.012\n",
      "  Neuroticism         : 0.194\n",
      "  Openness            : 0.156\n",
      "  Conscientiousness   : 0.015\n",
      "  Extraversion        : 0.133\n",
      "\n",
      "--- Sample 3 ---\n",
      "Text preview: A video's quality over quantity, so everyone can have a chance to watch it and that's why I've been ...\n",
      "\n",
      "GPT Predictions:\n",
      "  Agreeableness       : 0.680\n",
      "  Neuroticism         : 0.200\n",
      "  Openness            : 0.620\n",
      "  Conscientiousness   : 0.830\n",
      "  Extraversion        : 0.500\n",
      "\n",
      "Ground Truth:\n",
      "  Agreeableness       : 0.560\n",
      "  Neuroticism         : 0.625\n",
      "  Openness            : 0.522\n",
      "  Conscientiousness   : 0.524\n",
      "  Extraversion        : 0.467\n",
      "\n",
      "Absolute Errors:\n",
      "  Agreeableness       : 0.120\n",
      "  Neuroticism         : 0.425\n",
      "  Openness            : 0.098\n",
      "  Conscientiousness   : 0.306\n",
      "  Extraversion        : 0.033\n",
      "\n",
      "--- Sample 4 ---\n",
      "Text preview: You really want to. That's made things a lot easier. What I did was, I met people online virtually I...\n",
      "\n",
      "GPT Predictions:\n",
      "  Agreeableness       : 0.500\n",
      "  Neuroticism         : 0.300\n",
      "  Openness            : 0.560\n",
      "  Conscientiousness   : 0.620\n",
      "  Extraversion        : 0.580\n",
      "\n",
      "Ground Truth:\n",
      "  Agreeableness       : 0.714\n",
      "  Neuroticism         : 0.458\n",
      "  Openness            : 0.400\n",
      "  Conscientiousness   : 0.660\n",
      "  Extraversion        : 0.411\n",
      "\n",
      "Absolute Errors:\n",
      "  Agreeableness       : 0.214\n",
      "  Neuroticism         : 0.158\n",
      "  Openness            : 0.160\n",
      "  Conscientiousness   : 0.040\n",
      "  Extraversion        : 0.169\n",
      "\n",
      "--- Sample 5 ---\n",
      "Text preview: That's perfectly okay. The point isn't actually to find the answers in this exercise. The point is s...\n",
      "\n",
      "GPT Predictions:\n",
      "  Agreeableness       : 0.800\n",
      "  Neuroticism         : 0.250\n",
      "  Openness            : 0.700\n",
      "  Conscientiousness   : 0.600\n",
      "  Extraversion        : 0.300\n",
      "\n",
      "Ground Truth:\n",
      "  Agreeableness       : 0.385\n",
      "  Neuroticism         : 0.438\n",
      "  Openness            : 0.411\n",
      "  Conscientiousness   : 0.524\n",
      "  Extraversion        : 0.318\n",
      "\n",
      "Absolute Errors:\n",
      "  Agreeableness       : 0.415\n",
      "  Neuroticism         : 0.188\n",
      "  Openness            : 0.289\n",
      "  Conscientiousness   : 0.076\n",
      "  Extraversion        : 0.018\n",
      "\n",
      "--- Sample 6 ---\n",
      "Text preview: I had really bad eyesight. She's like, you can do this, you can read and I did it and I love it to t...\n",
      "\n",
      "GPT Predictions:\n",
      "  Agreeableness       : 0.520\n",
      "  Neuroticism         : 0.280\n",
      "  Openness            : 0.750\n",
      "  Conscientiousness   : 0.580\n",
      "  Extraversion        : 0.320\n",
      "\n",
      "Ground Truth:\n",
      "  Agreeableness       : 0.923\n",
      "  Neuroticism         : 0.844\n",
      "  Openness            : 0.822\n",
      "  Conscientiousness   : 0.709\n",
      "  Extraversion        : 0.832\n",
      "\n",
      "Absolute Errors:\n",
      "  Agreeableness       : 0.403\n",
      "  Neuroticism         : 0.564\n",
      "  Openness            : 0.072\n",
      "  Conscientiousness   : 0.129\n",
      "  Extraversion        : 0.512\n",
      "\n",
      "--- Sample 7 ---\n",
      "Text preview: ... ask you guys about, or talk to you about is, what kind of videos that you guys are wanting to se...\n",
      "\n",
      "GPT Predictions:\n",
      "  Agreeableness       : 0.720\n",
      "  Neuroticism         : 0.280\n",
      "  Openness            : 0.600\n",
      "  Conscientiousness   : 0.500\n",
      "  Extraversion        : 0.740\n",
      "\n",
      "Ground Truth:\n",
      "  Agreeableness       : 0.703\n",
      "  Neuroticism         : 0.813\n",
      "  Openness            : 0.878\n",
      "  Conscientiousness   : 0.874\n",
      "  Extraversion        : 0.757\n",
      "\n",
      "Absolute Errors:\n",
      "  Agreeableness       : 0.017\n",
      "  Neuroticism         : 0.533\n",
      "  Openness            : 0.278\n",
      "  Conscientiousness   : 0.374\n",
      "  Extraversion        : 0.017\n",
      "\n",
      "--- Sample 8 ---\n",
      "Text preview: Today, for in a month continuously, and we were studying some pretty difficult philosophy, really di...\n",
      "\n",
      "GPT Predictions:\n",
      "  Agreeableness       : 0.500\n",
      "  Neuroticism         : 0.540\n",
      "  Openness            : 0.780\n",
      "  Conscientiousness   : 0.790\n",
      "  Extraversion        : 0.500\n",
      "\n",
      "Ground Truth:\n",
      "  Agreeableness       : 0.670\n",
      "  Neuroticism         : 0.604\n",
      "  Openness            : 0.678\n",
      "  Conscientiousness   : 0.553\n",
      "  Extraversion        : 0.467\n",
      "\n",
      "Absolute Errors:\n",
      "  Agreeableness       : 0.170\n",
      "  Neuroticism         : 0.064\n",
      "  Openness            : 0.102\n",
      "  Conscientiousness   : 0.237\n",
      "  Extraversion        : 0.033\n",
      "\n",
      "--- Sample 9 ---\n",
      "Text preview: ... motion animation kind of things, probably Rudolph. It's the one that I remember the most, but I'...\n",
      "\n",
      "GPT Predictions:\n",
      "  Agreeableness       : 0.500\n",
      "  Neuroticism         : 0.560\n",
      "  Openness            : 0.430\n",
      "  Conscientiousness   : 0.500\n",
      "  Extraversion        : 0.500\n",
      "\n",
      "Ground Truth:\n",
      "  Agreeableness       : 0.615\n",
      "  Neuroticism         : 0.490\n",
      "  Openness            : 0.589\n",
      "  Conscientiousness   : 0.602\n",
      "  Extraversion        : 0.430\n",
      "\n",
      "Absolute Errors:\n",
      "  Agreeableness       : 0.115\n",
      "  Neuroticism         : 0.070\n",
      "  Openness            : 0.159\n",
      "  Conscientiousness   : 0.102\n",
      "  Extraversion        : 0.070\n",
      "\n",
      "--- Sample 10 ---\n",
      "Text preview: What I want to do about that, but yeah I actually do have like a blog block. That's all of my questi...\n",
      "\n",
      "GPT Predictions:\n",
      "  Agreeableness       : 0.500\n",
      "  Neuroticism         : 0.700\n",
      "  Openness            : 0.450\n",
      "  Conscientiousness   : 0.400\n",
      "  Extraversion        : 0.600\n",
      "\n",
      "Ground Truth:\n",
      "  Agreeableness       : 0.473\n",
      "  Neuroticism         : 0.573\n",
      "  Openness            : 0.467\n",
      "  Conscientiousness   : 0.466\n",
      "  Extraversion        : 0.542\n",
      "\n",
      "Absolute Errors:\n",
      "  Agreeableness       : 0.027\n",
      "  Neuroticism         : 0.127\n",
      "  Openness            : 0.017\n",
      "  Conscientiousness   : 0.066\n",
      "  Extraversion        : 0.058\n",
      "\n",
      "================================================================================\n",
      "OVERALL METRICS:\n",
      "================================================================================\n",
      "\n",
      "Overall MAE (all traits): 0.1699\n",
      "\n",
      "MAE per trait:\n",
      "  Agreeableness       : 0.1676\n",
      "  Neuroticism         : 0.2377\n",
      "  Openness            : 0.1702\n",
      "  Conscientiousness   : 0.1663\n",
      "  Extraversion        : 0.1078\n",
      "\n",
      "Additional Statistics:\n",
      "  Mean Squared Error (MSE): 0.0506\n",
      "  Root Mean Squared Error (RMSE): 0.2249\n",
      "  Max Absolute Error: 0.5637\n",
      "  Min Absolute Error: 0.0123\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Get first 10 rows from test data\n",
    "test_sample = annotation_transcription_test.head(10)\n",
    "\n",
    "print(f\"Analyzing {len(test_sample)} test samples...\")\n",
    "print(f\"Columns in test data: {test_sample.columns.tolist()}\\n\")\n",
    "\n",
    "# Extract texts from the test data\n",
    "test_texts = test_sample['text'].tolist()\n",
    "\n",
    "# Analyze personality traits using GPT\n",
    "print(\"Running GPT analysis on test samples...\")\n",
    "gpt_results = analyze_personality_batch(test_texts, model=\"gpt-5-mini-2025-08-07\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESULTS:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Prepare data for comparison\n",
    "# Trait order from GPT: [\"Agreeableness\", \"Neuroticism\", \"Openness\", \"Conscientiousness\", \"Extraversion\"]\n",
    "trait_names = [\"Agreeableness\", \"Neuroticism\", \"Openness\", \"Conscientiousness\", \"Extraversion\"]\n",
    "\n",
    "# Extract ground truth values from test data\n",
    "# Assuming the columns match the trait names (adjust if needed)\n",
    "ground_truth_cols = ['openness', 'conscientiousness', 'extraversion', 'agreeableness', 'neuroticism']\n",
    "\n",
    "# Create arrays to store predictions and ground truth\n",
    "all_predictions = []\n",
    "all_ground_truth = []\n",
    "\n",
    "for idx, result in enumerate(gpt_results):\n",
    "    print(f\"\\n--- Sample {idx + 1} ---\")\n",
    "    \n",
    "    if 'error' in result:\n",
    "        print(f\"Error: {result['error']}\")\n",
    "        continue\n",
    "    \n",
    "    # Get GPT predictions\n",
    "    gpt_scores = result.get('scores', [])\n",
    "    \n",
    "    # Get ground truth from test data (convert to same order as GPT output)\n",
    "    row = test_sample.iloc[idx]\n",
    "    \n",
    "    # Reorder ground truth to match GPT output order\n",
    "    # GPT order: [\"Agreeableness\", \"Neuroticism\", \"Openness\", \"Conscientiousness\", \"Extraversion\"]\n",
    "    ground_truth = [\n",
    "        row['agreeableness'],\n",
    "        row['neuroticism'],\n",
    "        row['openness'],\n",
    "        row['conscientiousness'],\n",
    "        row['extraversion']\n",
    "    ]\n",
    "    \n",
    "    print(f\"Text preview: {test_texts[idx][:100]}...\")\n",
    "    print(f\"\\nGPT Predictions:\")\n",
    "    for trait, score in zip(trait_names, gpt_scores):\n",
    "        print(f\"  {trait:20s}: {score:.3f}\")\n",
    "    \n",
    "    print(f\"\\nGround Truth:\")\n",
    "    for trait, score in zip(trait_names, ground_truth):\n",
    "        print(f\"  {trait:20s}: {score:.3f}\")\n",
    "    \n",
    "    print(f\"\\nAbsolute Errors:\")\n",
    "    for trait, pred, true in zip(trait_names, gpt_scores, ground_truth):\n",
    "        error = abs(pred - true)\n",
    "        print(f\"  {trait:20s}: {error:.3f}\")\n",
    "    \n",
    "    all_predictions.append(gpt_scores)\n",
    "    all_ground_truth.append(ground_truth)\n",
    "\n",
    "# Calculate overall MAE\n",
    "if all_predictions:\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_ground_truth = np.array(all_ground_truth)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"OVERALL METRICS:\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Overall MAE across all traits and samples\n",
    "    overall_mae = mean_absolute_error(all_ground_truth.flatten(), all_predictions.flatten())\n",
    "    print(f\"\\nOverall MAE (all traits): {overall_mae:.4f}\")\n",
    "    \n",
    "    # MAE per trait\n",
    "    print(f\"\\nMAE per trait:\")\n",
    "    for i, trait in enumerate(trait_names):\n",
    "        trait_mae = mean_absolute_error(all_ground_truth[:, i], all_predictions[:, i])\n",
    "        print(f\"  {trait:20s}: {trait_mae:.4f}\")\n",
    "    \n",
    "    # Additional statistics\n",
    "    print(f\"\\nAdditional Statistics:\")\n",
    "    print(f\"  Mean Squared Error (MSE): {np.mean((all_ground_truth - all_predictions) ** 2):.4f}\")\n",
    "    print(f\"  Root Mean Squared Error (RMSE): {np.sqrt(np.mean((all_ground_truth - all_predictions) ** 2)):.4f}\")\n",
    "    print(f\"  Max Absolute Error: {np.max(np.abs(all_ground_truth - all_predictions)):.4f}\")\n",
    "    print(f\"  Min Absolute Error: {np.min(np.abs(all_ground_truth - all_predictions)):.4f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\nNo successful predictions to calculate MAE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93f0d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gpt5 mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34fd70c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 10 test samples...\n",
      "Columns in test data: ['file', 'text', 'extraversion', 'neuroticism', 'agreeableness', 'conscientiousness', 'openness']\n",
      "\n",
      "Running GPT analysis on test samples (making 3 predictions per text)...\n",
      "\n",
      "--- Prediction Run 1/3 ---\n",
      "Analyzing text 1/10...\n",
      "Analyzing text 2/10...\n",
      "Analyzing text 3/10...\n",
      "Analyzing text 4/10...\n",
      "Analyzing text 5/10...\n",
      "Analyzing text 6/10...\n",
      "Analyzing text 7/10...\n",
      "Analyzing text 8/10...\n",
      "Analyzing text 9/10...\n",
      "Analyzing text 10/10...\n",
      "\n",
      "--- Prediction Run 2/3 ---\n",
      "Analyzing text 1/10...\n",
      "Analyzing text 2/10...\n",
      "Analyzing text 3/10...\n",
      "Analyzing text 4/10...\n",
      "Analyzing text 5/10...\n",
      "Analyzing text 6/10...\n",
      "Analyzing text 7/10...\n",
      "Analyzing text 8/10...\n",
      "Analyzing text 9/10...\n",
      "Analyzing text 10/10...\n",
      "\n",
      "--- Prediction Run 3/3 ---\n",
      "Analyzing text 1/10...\n",
      "Analyzing text 2/10...\n",
      "Analyzing text 3/10...\n",
      "Analyzing text 4/10...\n",
      "Analyzing text 5/10...\n",
      "Analyzing text 6/10...\n",
      "Analyzing text 7/10...\n",
      "Analyzing text 8/10...\n",
      "Analyzing text 9/10...\n",
      "Analyzing text 10/10...\n",
      "\n",
      "================================================================================\n",
      "RESULTS (with Averaged Predictions):\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Sample 1\n",
      "================================================================================\n",
      "Text preview: ... Going nuts from another room, run in there to check, there's no [inaudible 00:00:37], but it was...\n",
      "\n",
      "Individual Predictions (across 3 runs):\n",
      "  Run 1:\n",
      "    Agreeableness       : 0.500\n",
      "    Neuroticism         : 0.700\n",
      "    Openness            : 0.400\n",
      "    Conscientiousness   : 0.500\n",
      "    Extraversion        : 0.500\n",
      "  Run 2:\n",
      "    Agreeableness       : 0.500\n",
      "    Neuroticism         : 0.720\n",
      "    Openness            : 0.390\n",
      "    Conscientiousness   : 0.560\n",
      "    Extraversion        : 0.280\n",
      "  Run 3:\n",
      "    Agreeableness       : 0.500\n",
      "    Neuroticism         : 0.750\n",
      "    Openness            : 0.400\n",
      "    Conscientiousness   : 0.500\n",
      "    Extraversion        : 0.300\n",
      "\n",
      "Averaged GPT Predictions (±std):\n",
      "  Agreeableness       : 0.500 (±0.000)\n",
      "  Neuroticism         : 0.723 (±0.021)\n",
      "  Openness            : 0.397 (±0.005)\n",
      "  Conscientiousness   : 0.520 (±0.028)\n",
      "  Extraversion        : 0.360 (±0.099)\n",
      "\n",
      "Ground Truth:\n",
      "  Agreeableness       : 0.681\n",
      "  Neuroticism         : 0.646\n",
      "  Openness            : 0.822\n",
      "  Conscientiousness   : 0.670\n",
      "  Extraversion        : 0.486\n",
      "\n",
      "Absolute Errors (using averaged predictions):\n",
      "  Agreeableness       : 0.181\n",
      "  Neuroticism         : 0.078\n",
      "  Openness            : 0.426\n",
      "  Conscientiousness   : 0.150\n",
      "  Extraversion        : 0.126\n",
      "\n",
      "================================================================================\n",
      "Sample 2\n",
      "================================================================================\n",
      "Text preview: I've got a little bit to go but we need you there so...I have decided to do a Q&A video. Obviously I...\n",
      "\n",
      "Individual Predictions (across 3 runs):\n",
      "  Run 1:\n",
      "    Agreeableness       : 0.650\n",
      "    Neuroticism         : 0.700\n",
      "    Openness            : 0.580\n",
      "    Conscientiousness   : 0.600\n",
      "    Extraversion        : 0.700\n",
      "  Run 2:\n",
      "    Agreeableness       : 0.660\n",
      "    Neuroticism         : 0.650\n",
      "    Openness            : 0.450\n",
      "    Conscientiousness   : 0.580\n",
      "    Extraversion        : 0.620\n",
      "  Run 3:\n",
      "    Agreeableness       : 0.660\n",
      "    Neuroticism         : 0.650\n",
      "    Openness            : 0.520\n",
      "    Conscientiousness   : 0.600\n",
      "    Extraversion        : 0.580\n",
      "\n",
      "Averaged GPT Predictions (±std):\n",
      "  Agreeableness       : 0.657 (±0.005)\n",
      "  Neuroticism         : 0.667 (±0.024)\n",
      "  Openness            : 0.517 (±0.053)\n",
      "  Conscientiousness   : 0.593 (±0.009)\n",
      "  Extraversion        : 0.633 (±0.050)\n",
      "\n",
      "Ground Truth:\n",
      "  Agreeableness       : 0.692\n",
      "  Neuroticism         : 0.594\n",
      "  Openness            : 0.656\n",
      "  Conscientiousness   : 0.515\n",
      "  Extraversion        : 0.617\n",
      "\n",
      "Absolute Errors (using averaged predictions):\n",
      "  Agreeableness       : 0.036\n",
      "  Neuroticism         : 0.073\n",
      "  Openness            : 0.139\n",
      "  Conscientiousness   : 0.079\n",
      "  Extraversion        : 0.017\n",
      "\n",
      "================================================================================\n",
      "Sample 3\n",
      "================================================================================\n",
      "Text preview: A video's quality over quantity, so everyone can have a chance to watch it and that's why I've been ...\n",
      "\n",
      "Individual Predictions (across 3 runs):\n",
      "  Run 1:\n",
      "    Agreeableness       : 0.680\n",
      "    Neuroticism         : 0.250\n",
      "    Openness            : 0.500\n",
      "    Conscientiousness   : 0.780\n",
      "    Extraversion        : 0.350\n",
      "  Run 2:\n",
      "    Agreeableness       : 0.750\n",
      "    Neuroticism         : 0.250\n",
      "    Openness            : 0.600\n",
      "    Conscientiousness   : 0.850\n",
      "    Extraversion        : 0.460\n",
      "  Run 3:\n",
      "    Agreeableness       : 0.680\n",
      "    Neuroticism         : 0.280\n",
      "    Openness            : 0.580\n",
      "    Conscientiousness   : 0.790\n",
      "    Extraversion        : 0.460\n",
      "\n",
      "Averaged GPT Predictions (±std):\n",
      "  Agreeableness       : 0.703 (±0.033)\n",
      "  Neuroticism         : 0.260 (±0.014)\n",
      "  Openness            : 0.560 (±0.043)\n",
      "  Conscientiousness   : 0.807 (±0.031)\n",
      "  Extraversion        : 0.423 (±0.052)\n",
      "\n",
      "Ground Truth:\n",
      "  Agreeableness       : 0.560\n",
      "  Neuroticism         : 0.625\n",
      "  Openness            : 0.522\n",
      "  Conscientiousness   : 0.524\n",
      "  Extraversion        : 0.467\n",
      "\n",
      "Absolute Errors (using averaged predictions):\n",
      "  Agreeableness       : 0.143\n",
      "  Neuroticism         : 0.365\n",
      "  Openness            : 0.038\n",
      "  Conscientiousness   : 0.282\n",
      "  Extraversion        : 0.044\n",
      "\n",
      "================================================================================\n",
      "Sample 4\n",
      "================================================================================\n",
      "Text preview: You really want to. That's made things a lot easier. What I did was, I met people online virtually I...\n",
      "\n",
      "Individual Predictions (across 3 runs):\n",
      "  Run 1:\n",
      "    Agreeableness       : 0.550\n",
      "    Neuroticism         : 0.400\n",
      "    Openness            : 0.560\n",
      "    Conscientiousness   : 0.680\n",
      "    Extraversion        : 0.420\n",
      "  Run 2:\n",
      "    Agreeableness       : 0.580\n",
      "    Neuroticism         : 0.250\n",
      "    Openness            : 0.530\n",
      "    Conscientiousness   : 0.620\n",
      "    Extraversion        : 0.430\n",
      "  Run 3:\n",
      "    Agreeableness       : 0.550\n",
      "    Neuroticism         : 0.450\n",
      "    Openness            : 0.540\n",
      "    Conscientiousness   : 0.700\n",
      "    Extraversion        : 0.450\n",
      "\n",
      "Averaged GPT Predictions (±std):\n",
      "  Agreeableness       : 0.560 (±0.014)\n",
      "  Neuroticism         : 0.367 (±0.085)\n",
      "  Openness            : 0.543 (±0.012)\n",
      "  Conscientiousness   : 0.667 (±0.034)\n",
      "  Extraversion        : 0.433 (±0.012)\n",
      "\n",
      "Ground Truth:\n",
      "  Agreeableness       : 0.714\n",
      "  Neuroticism         : 0.458\n",
      "  Openness            : 0.400\n",
      "  Conscientiousness   : 0.660\n",
      "  Extraversion        : 0.411\n",
      "\n",
      "Absolute Errors (using averaged predictions):\n",
      "  Agreeableness       : 0.154\n",
      "  Neuroticism         : 0.092\n",
      "  Openness            : 0.143\n",
      "  Conscientiousness   : 0.006\n",
      "  Extraversion        : 0.022\n",
      "\n",
      "================================================================================\n",
      "Sample 5\n",
      "================================================================================\n",
      "Text preview: That's perfectly okay. The point isn't actually to find the answers in this exercise. The point is s...\n",
      "\n",
      "Individual Predictions (across 3 runs):\n",
      "  Run 1:\n",
      "    Agreeableness       : 0.700\n",
      "    Neuroticism         : 0.250\n",
      "    Openness            : 0.650\n",
      "    Conscientiousness   : 0.780\n",
      "    Extraversion        : 0.250\n",
      "  Run 2:\n",
      "    Agreeableness       : 0.600\n",
      "    Neuroticism         : 0.350\n",
      "    Openness            : 0.750\n",
      "    Conscientiousness   : 0.600\n",
      "    Extraversion        : 0.300\n",
      "  Run 3:\n",
      "    Agreeableness       : 0.600\n",
      "    Neuroticism         : 0.250\n",
      "    Openness            : 0.780\n",
      "    Conscientiousness   : 0.660\n",
      "    Extraversion        : 0.280\n",
      "\n",
      "Averaged GPT Predictions (±std):\n",
      "  Agreeableness       : 0.633 (±0.047)\n",
      "  Neuroticism         : 0.283 (±0.047)\n",
      "  Openness            : 0.727 (±0.056)\n",
      "  Conscientiousness   : 0.680 (±0.075)\n",
      "  Extraversion        : 0.277 (±0.021)\n",
      "\n",
      "Ground Truth:\n",
      "  Agreeableness       : 0.385\n",
      "  Neuroticism         : 0.438\n",
      "  Openness            : 0.411\n",
      "  Conscientiousness   : 0.524\n",
      "  Extraversion        : 0.318\n",
      "\n",
      "Absolute Errors (using averaged predictions):\n",
      "  Agreeableness       : 0.249\n",
      "  Neuroticism         : 0.154\n",
      "  Openness            : 0.316\n",
      "  Conscientiousness   : 0.156\n",
      "  Extraversion        : 0.041\n",
      "\n",
      "================================================================================\n",
      "Sample 6\n",
      "================================================================================\n",
      "Text preview: I had really bad eyesight. She's like, you can do this, you can read and I did it and I love it to t...\n",
      "\n",
      "Individual Predictions (across 3 runs):\n",
      "  Run 1:\n",
      "    Agreeableness       : 0.500\n",
      "    Neuroticism         : 0.250\n",
      "    Openness            : 0.660\n",
      "    Conscientiousness   : 0.580\n",
      "    Extraversion        : 0.280\n",
      "  Run 2:\n",
      "    Agreeableness       : 0.500\n",
      "    Neuroticism         : 0.500\n",
      "    Openness            : 0.750\n",
      "    Conscientiousness   : 0.550\n",
      "    Extraversion        : 0.400\n",
      "  Run 3:\n",
      "    Agreeableness       : 0.600\n",
      "    Neuroticism         : 0.300\n",
      "    Openness            : 0.800\n",
      "    Conscientiousness   : 0.650\n",
      "    Extraversion        : 0.250\n",
      "\n",
      "Averaged GPT Predictions (±std):\n",
      "  Agreeableness       : 0.533 (±0.047)\n",
      "  Neuroticism         : 0.350 (±0.108)\n",
      "  Openness            : 0.737 (±0.058)\n",
      "  Conscientiousness   : 0.593 (±0.042)\n",
      "  Extraversion        : 0.310 (±0.065)\n",
      "\n",
      "Ground Truth:\n",
      "  Agreeableness       : 0.923\n",
      "  Neuroticism         : 0.844\n",
      "  Openness            : 0.822\n",
      "  Conscientiousness   : 0.709\n",
      "  Extraversion        : 0.832\n",
      "\n",
      "Absolute Errors (using averaged predictions):\n",
      "  Agreeableness       : 0.390\n",
      "  Neuroticism         : 0.494\n",
      "  Openness            : 0.086\n",
      "  Conscientiousness   : 0.115\n",
      "  Extraversion        : 0.522\n",
      "\n",
      "================================================================================\n",
      "Sample 7\n",
      "================================================================================\n",
      "Text preview: ... ask you guys about, or talk to you about is, what kind of videos that you guys are wanting to se...\n",
      "\n",
      "Individual Predictions (across 3 runs):\n",
      "  Run 1:\n",
      "    Agreeableness       : 0.580\n",
      "    Neuroticism         : 0.230\n",
      "    Openness            : 0.520\n",
      "    Conscientiousness   : 0.550\n",
      "    Extraversion        : 0.600\n",
      "  Run 2:\n",
      "    Agreeableness       : 0.800\n",
      "    Neuroticism         : 0.200\n",
      "    Openness            : 0.750\n",
      "    Conscientiousness   : 0.650\n",
      "    Extraversion        : 0.750\n",
      "  Run 3:\n",
      "    Agreeableness       : 0.780\n",
      "    Neuroticism         : 0.250\n",
      "    Openness            : 0.660\n",
      "    Conscientiousness   : 0.660\n",
      "    Extraversion        : 0.540\n",
      "\n",
      "Averaged GPT Predictions (±std):\n",
      "  Agreeableness       : 0.720 (±0.099)\n",
      "  Neuroticism         : 0.227 (±0.021)\n",
      "  Openness            : 0.643 (±0.095)\n",
      "  Conscientiousness   : 0.620 (±0.050)\n",
      "  Extraversion        : 0.630 (±0.088)\n",
      "\n",
      "Ground Truth:\n",
      "  Agreeableness       : 0.703\n",
      "  Neuroticism         : 0.813\n",
      "  Openness            : 0.878\n",
      "  Conscientiousness   : 0.874\n",
      "  Extraversion        : 0.757\n",
      "\n",
      "Absolute Errors (using averaged predictions):\n",
      "  Agreeableness       : 0.017\n",
      "  Neuroticism         : 0.586\n",
      "  Openness            : 0.234\n",
      "  Conscientiousness   : 0.254\n",
      "  Extraversion        : 0.127\n",
      "\n",
      "================================================================================\n",
      "Sample 8\n",
      "================================================================================\n",
      "Text preview: Today, for in a month continuously, and we were studying some pretty difficult philosophy, really di...\n",
      "\n",
      "Individual Predictions (across 3 runs):\n",
      "  Run 1:\n",
      "    Agreeableness       : 0.500\n",
      "    Neuroticism         : 0.520\n",
      "    Openness            : 0.650\n",
      "    Conscientiousness   : 0.800\n",
      "    Extraversion        : 0.350\n",
      "  Run 2:\n",
      "    Agreeableness       : 0.500\n",
      "    Neuroticism         : 0.250\n",
      "    Openness            : 0.780\n",
      "    Conscientiousness   : 0.790\n",
      "    Extraversion        : 0.280\n",
      "  Run 3:\n",
      "    Agreeableness       : 0.500\n",
      "    Neuroticism         : 0.500\n",
      "    Openness            : 0.820\n",
      "    Conscientiousness   : 0.830\n",
      "    Extraversion        : 0.350\n",
      "\n",
      "Averaged GPT Predictions (±std):\n",
      "  Agreeableness       : 0.500 (±0.000)\n",
      "  Neuroticism         : 0.423 (±0.123)\n",
      "  Openness            : 0.750 (±0.073)\n",
      "  Conscientiousness   : 0.807 (±0.017)\n",
      "  Extraversion        : 0.327 (±0.033)\n",
      "\n",
      "Ground Truth:\n",
      "  Agreeableness       : 0.670\n",
      "  Neuroticism         : 0.604\n",
      "  Openness            : 0.678\n",
      "  Conscientiousness   : 0.553\n",
      "  Extraversion        : 0.467\n",
      "\n",
      "Absolute Errors (using averaged predictions):\n",
      "  Agreeableness       : 0.170\n",
      "  Neuroticism         : 0.181\n",
      "  Openness            : 0.072\n",
      "  Conscientiousness   : 0.253\n",
      "  Extraversion        : 0.141\n",
      "\n",
      "================================================================================\n",
      "Sample 9\n",
      "================================================================================\n",
      "Text preview: ... motion animation kind of things, probably Rudolph. It's the one that I remember the most, but I'...\n",
      "\n",
      "Individual Predictions (across 3 runs):\n",
      "  Run 1:\n",
      "    Agreeableness       : 0.500\n",
      "    Neuroticism         : 0.490\n",
      "    Openness            : 0.500\n",
      "    Conscientiousness   : 0.500\n",
      "    Extraversion        : 0.400\n",
      "  Run 2:\n",
      "    Agreeableness       : 0.500\n",
      "    Neuroticism         : 0.550\n",
      "    Openness            : 0.450\n",
      "    Conscientiousness   : 0.500\n",
      "    Extraversion        : 0.400\n",
      "  Run 3:\n",
      "    Agreeableness       : 0.500\n",
      "    Neuroticism         : 0.420\n",
      "    Openness            : 0.400\n",
      "    Conscientiousness   : 0.500\n",
      "    Extraversion        : 0.500\n",
      "\n",
      "Averaged GPT Predictions (±std):\n",
      "  Agreeableness       : 0.500 (±0.000)\n",
      "  Neuroticism         : 0.487 (±0.053)\n",
      "  Openness            : 0.450 (±0.041)\n",
      "  Conscientiousness   : 0.500 (±0.000)\n",
      "  Extraversion        : 0.433 (±0.047)\n",
      "\n",
      "Ground Truth:\n",
      "  Agreeableness       : 0.615\n",
      "  Neuroticism         : 0.490\n",
      "  Openness            : 0.589\n",
      "  Conscientiousness   : 0.602\n",
      "  Extraversion        : 0.430\n",
      "\n",
      "Absolute Errors (using averaged predictions):\n",
      "  Agreeableness       : 0.115\n",
      "  Neuroticism         : 0.003\n",
      "  Openness            : 0.139\n",
      "  Conscientiousness   : 0.102\n",
      "  Extraversion        : 0.003\n",
      "\n",
      "================================================================================\n",
      "Sample 10\n",
      "================================================================================\n",
      "Text preview: What I want to do about that, but yeah I actually do have like a blog block. That's all of my questi...\n",
      "\n",
      "Individual Predictions (across 3 runs):\n",
      "  Run 1:\n",
      "    Agreeableness       : 0.500\n",
      "    Neuroticism         : 0.600\n",
      "    Openness            : 0.380\n",
      "    Conscientiousness   : 0.420\n",
      "    Extraversion        : 0.320\n",
      "  Run 2:\n",
      "    Agreeableness       : 0.500\n",
      "    Neuroticism         : 0.400\n",
      "    Openness            : 0.400\n",
      "    Conscientiousness   : 0.460\n",
      "    Extraversion        : 0.250\n",
      "  Run 3:\n",
      "    Agreeableness       : 0.600\n",
      "    Neuroticism         : 0.450\n",
      "    Openness            : 0.500\n",
      "    Conscientiousness   : 0.500\n",
      "    Extraversion        : 0.250\n",
      "\n",
      "Averaged GPT Predictions (±std):\n",
      "  Agreeableness       : 0.533 (±0.047)\n",
      "  Neuroticism         : 0.483 (±0.085)\n",
      "  Openness            : 0.427 (±0.052)\n",
      "  Conscientiousness   : 0.460 (±0.033)\n",
      "  Extraversion        : 0.273 (±0.033)\n",
      "\n",
      "Ground Truth:\n",
      "  Agreeableness       : 0.473\n",
      "  Neuroticism         : 0.573\n",
      "  Openness            : 0.467\n",
      "  Conscientiousness   : 0.466\n",
      "  Extraversion        : 0.542\n",
      "\n",
      "Absolute Errors (using averaged predictions):\n",
      "  Agreeableness       : 0.061\n",
      "  Neuroticism         : 0.090\n",
      "  Openness            : 0.040\n",
      "  Conscientiousness   : 0.006\n",
      "  Extraversion        : 0.269\n",
      "\n",
      "================================================================================\n",
      "OVERALL METRICS (using averaged predictions):\n",
      "================================================================================\n",
      "\n",
      "Overall MAE (all traits): 0.1595\n",
      "\n",
      "MAE per trait:\n",
      "  Agreeableness       : 0.1516\n",
      "  Neuroticism         : 0.2114\n",
      "  Openness            : 0.1632\n",
      "  Conscientiousness   : 0.1404\n",
      "  Extraversion        : 0.1311\n",
      "\n",
      "Additional Statistics:\n",
      "  Mean Squared Error (MSE): 0.0448\n",
      "  Root Mean Squared Error (RMSE): 0.2116\n",
      "  Max Absolute Error: 0.5858\n",
      "  Min Absolute Error: 0.0029\n",
      "\n",
      "Prediction Variance Analysis:\n",
      "  Average prediction uncertainty (std) per trait:\n",
      "    Agreeableness       : 0.0293\n",
      "    Neuroticism         : 0.0580\n",
      "    Openness            : 0.0488\n",
      "    Conscientiousness   : 0.0319\n",
      "    Extraversion        : 0.0500\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Get first 10 rows from test data\n",
    "test_sample = annotation_transcription_test.head(10)\n",
    "\n",
    "print(f\"Analyzing {len(test_sample)} test samples...\")\n",
    "print(f\"Columns in test data: {test_sample.columns.tolist()}\\n\")\n",
    "\n",
    "# Extract texts from the test data\n",
    "test_texts = test_sample['text'].tolist()\n",
    "\n",
    "# Number of predictions per text for averaging\n",
    "num_predictions = 3\n",
    "\n",
    "# Analyze personality traits using GPT - make multiple predictions per text\n",
    "print(f\"Running GPT analysis on test samples (making {num_predictions} predictions per text)...\")\n",
    "all_runs_results = []\n",
    "\n",
    "for run in range(num_predictions):\n",
    "    print(f\"\\n--- Prediction Run {run + 1}/{num_predictions} ---\")\n",
    "    gpt_results = analyze_personality_batch(test_texts, model=\"gpt-5-nano-2025-08-07\")\n",
    "    all_runs_results.append(gpt_results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESULTS (with Averaged Predictions):\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Prepare data for comparison\n",
    "# Trait order from GPT: [\"Agreeableness\", \"Neuroticism\", \"Openness\", \"Conscientiousness\", \"Extraversion\"]\n",
    "trait_names = [\"Agreeableness\", \"Neuroticism\", \"Openness\", \"Conscientiousness\", \"Extraversion\"]\n",
    "\n",
    "# Create arrays to store predictions and ground truth\n",
    "all_predictions = []\n",
    "all_ground_truth = []\n",
    "all_individual_predictions = []  # Store all 3 predictions for variance analysis\n",
    "\n",
    "for idx in range(len(test_texts)):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Sample {idx + 1}\")\n",
    "    print('='*80)\n",
    "    \n",
    "    # Collect all predictions for this text from all runs\n",
    "    predictions_for_text = []\n",
    "    has_error = False\n",
    "    \n",
    "    for run in range(num_predictions):\n",
    "        result = all_runs_results[run][idx]\n",
    "        if 'error' in result:\n",
    "            print(f\"Error in run {run + 1}: {result['error']}\")\n",
    "            has_error = True\n",
    "            break\n",
    "        predictions_for_text.append(result.get('scores', []))\n",
    "    \n",
    "    if has_error:\n",
    "        continue\n",
    "    \n",
    "    # Calculate average predictions across all runs\n",
    "    predictions_array = np.array(predictions_for_text)  # Shape: (num_predictions, 5)\n",
    "    avg_predictions = np.mean(predictions_array, axis=0)  # Average across runs\n",
    "    std_predictions = np.std(predictions_array, axis=0)   # Standard deviation for uncertainty\n",
    "    \n",
    "    # Get ground truth from test data\n",
    "    row = test_sample.iloc[idx]\n",
    "    ground_truth = [\n",
    "        row['agreeableness'],\n",
    "        row['neuroticism'],\n",
    "        row['openness'],\n",
    "        row['conscientiousness'],\n",
    "        row['extraversion']\n",
    "    ]\n",
    "    \n",
    "    print(f\"Text preview: {test_texts[idx][:100]}...\")\n",
    "    \n",
    "    # Show individual predictions\n",
    "    print(f\"\\nIndividual Predictions (across {num_predictions} runs):\")\n",
    "    for run_num, pred in enumerate(predictions_for_text, 1):\n",
    "        print(f\"  Run {run_num}:\")\n",
    "        for trait, score in zip(trait_names, pred):\n",
    "            print(f\"    {trait:20s}: {score:.3f}\")\n",
    "    \n",
    "    # Show averaged predictions with standard deviation\n",
    "    print(f\"\\nAveraged GPT Predictions (±std):\")\n",
    "    for trait, avg_score, std_score in zip(trait_names, avg_predictions, std_predictions):\n",
    "        print(f\"  {trait:20s}: {avg_score:.3f} (±{std_score:.3f})\")\n",
    "    \n",
    "    print(f\"\\nGround Truth:\")\n",
    "    for trait, score in zip(trait_names, ground_truth):\n",
    "        print(f\"  {trait:20s}: {score:.3f}\")\n",
    "    \n",
    "    print(f\"\\nAbsolute Errors (using averaged predictions):\")\n",
    "    for trait, avg_pred, true in zip(trait_names, avg_predictions, ground_truth):\n",
    "        error = abs(avg_pred - true)\n",
    "        print(f\"  {trait:20s}: {error:.3f}\")\n",
    "    \n",
    "    all_predictions.append(avg_predictions)\n",
    "    all_ground_truth.append(ground_truth)\n",
    "    all_individual_predictions.append(predictions_array)\n",
    "\n",
    "# Calculate overall MAE\n",
    "if all_predictions:\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_ground_truth = np.array(all_ground_truth)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"OVERALL METRICS (using averaged predictions):\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Overall MAE across all traits and samples\n",
    "    overall_mae = mean_absolute_error(all_ground_truth.flatten(), all_predictions.flatten())\n",
    "    print(f\"\\nOverall MAE (all traits): {overall_mae:.4f}\")\n",
    "    \n",
    "    # MAE per trait\n",
    "    print(f\"\\nMAE per trait:\")\n",
    "    for i, trait in enumerate(trait_names):\n",
    "        trait_mae = mean_absolute_error(all_ground_truth[:, i], all_predictions[:, i])\n",
    "        print(f\"  {trait:20s}: {trait_mae:.4f}\")\n",
    "    \n",
    "    # Additional statistics\n",
    "    print(f\"\\nAdditional Statistics:\")\n",
    "    print(f\"  Mean Squared Error (MSE): {np.mean((all_ground_truth - all_predictions) ** 2):.4f}\")\n",
    "    print(f\"  Root Mean Squared Error (RMSE): {np.sqrt(np.mean((all_ground_truth - all_predictions) ** 2)):.4f}\")\n",
    "    print(f\"  Max Absolute Error: {np.max(np.abs(all_ground_truth - all_predictions)):.4f}\")\n",
    "    print(f\"  Min Absolute Error: {np.min(np.abs(all_ground_truth - all_predictions)):.4f}\")\n",
    "    \n",
    "    # Prediction variance analysis\n",
    "    print(f\"\\nPrediction Variance Analysis:\")\n",
    "    all_individual_predictions_array = np.array(all_individual_predictions)  # Shape: (samples, runs, traits)\n",
    "    mean_std_per_trait = np.mean(np.std(all_individual_predictions_array, axis=1), axis=0)  # Average std across samples\n",
    "    print(f\"  Average prediction uncertainty (std) per trait:\")\n",
    "    for trait, std_val in zip(trait_names, mean_std_per_trait):\n",
    "        print(f\"    {trait:20s}: {std_val:.4f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\nNo successful predictions to calculate MAE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed04abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt-5-nano-2025-08-07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42eeafde",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt-5-nano-2025-08-07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af46ff19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfe012b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d61a8a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03157c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9476ff56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
